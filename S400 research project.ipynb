{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The Synopsis</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Project Title:\n",
    "Analyzing the Impact of Cross-Asset Data and Correlation on Price Prediction\n",
    "\n",
    "Research Questions:\n",
    "  Does the inclusion of cross-asset technical indicators significantly improve prediction accuracy compared to single-asset models?\n",
    "    \n",
    "   Is information from correlated assets the better at enhancing prediction performance than non correlated assets?\n",
    "    \n",
    "   Between linear and logistic regression which has better performance thanks to cross asset data?\n",
    "\n",
    "Brief Synopsis:\n",
    "The core objective of my research is to investigate whether incorporating data from other assets (cross-asset data) can improve the accuracy of price prediction models. Traditionally, predictive models for an asset (e.g., a stock or currency pair) rely solely on its own historical data and indicators. However, I aim to explore whether including data from related assets (e.g., other stocks or FX pairs) can provide additional predictive power.\n",
    "\n",
    "For example, if building a linear regression model to predict Microsoft stock prices, instead of using only Microsoft’s indicators (e.g., OHLC, RSI, MACD), I would also incorporate indicators from related assets like Apple or Google stock. This approach extends to FX currency pairs, where I will examine whether data from other pairs (e.g., using EURUSD data to predict GBPUSD) improves predictions.\n",
    "\n",
    "Data Preparation:\n",
    "\n",
    "I have dataset with 9 FX currency pairs and 9 stocks. EURUSD, EURGBP, GBPUSD, USDJPY, AUDJPY, EURJPY, AUDUSD, GBPAUD, USDCHF, USDCAD, META, AAPL, AMZN, NFLX, GOOGL, JPM, GS, C, AXP.\n",
    "\n",
    "Here is the complete list of explanatory variables with their column names in brackets:  \n",
    "\n",
    "Weighted price average [weighted], Open-Close delta [ocDelta], High-Low delta [hlDelta], High-Low to Open-Close ratio [hl_oc], Percent price change [Percent_Change], Candle direction binary [CandleDirection], Simple Moving Average 14-period [SMA], Exponential Moving Average 14-period [EMA], Double Exponential Moving Average 14-period [DEMA], Triple Exponential Moving Average 14-period [TEMA], Rate of Change 14-period [ROC], Average True Range 14-period [ATR], Normalized Average True Range 14-period [NATR], Bollinger Bands Upper 14-period [BBANDS_UPPER], Bollinger Bands Middle 14-period [BBANDS_MIDDLE], Bollinger Bands Lower 14-period [BBANDS_LOWER], Aroon Up 14-period [Aroon_Up], Aroon Down 14-period [Aroon_Down], Aroon Oscillator 14-period [Aroon_Osc], Average Directional Index 14-period [ADX], Commodity Channel Index 14-period [CCI], Rate of Change Percentage 14-period [ROCP], Williams %R 14-period [WilliamsR], Chaikin Oscillator 14/28-period [ADOSC], Parabolic SAR [SAR], Weighted price minus SMA [w-SMA], Weighted price minus Bollinger Upper [w-UPPER], Weighted price minus Bollinger Lower [w-LOWER], Hammer pattern [CDLHAMMER], Inverted Hammer pattern [CDLINVERTEDHAMMER], Hanging Man pattern [CDLHANGINGMAN], Shooting Star pattern [CDLSHOOTINGSTAR], Engulfing pattern [CDLENGULFING], Harami pattern [CDLHARAMI], Piercing Line pattern [CDLPIERCING], Dark Cloud Cover pattern [CDLDARKCLOUDCOVER], Morning Star pattern [CDLMORNINGSTAR], Evening Star pattern [CDLEVENINGSTAR].  \n",
    "\n",
    "Each variable is suffixed with the asset symbol (e.g., [SMA_AAPL] for Apple’s Simple Moving Average). Candlestick pattern variables return 0 (no pattern), +100 (bullish), or -100 (bearish).\n",
    "\n",
    "The response variables in this study consist of two key metrics designed to capture future price movements. The first is NextCandleDirectionR [NextCandleDirectionR], a continuous variable that measures the actual numerical difference between an asset's closing price on the next trading day and its current closing price (calculated as Close_{t+1} - Close_t).The second is NextCandleDirectionC [NextCandleDirectionC], a binary classification variable that simplifies the prediction task by encoding whether the next day's closing price will be higher than the current day's close (1 if Close_{t+1} > Close_t, otherwise 0).\n",
    "\n",
    "The variables are computed for all 18 assets (9 FX pairs and 9 stocks) and aligned with the timestamped explanatory variables (inner join by date) to ensure consistent temporal relationships in the analysis.\n",
    "\n",
    "Model Building:\n",
    "\n",
    "Baseline Models: Conduct  linear regression and  logistic regression for each asset using only its own data.\n",
    "\n",
    "Cross-Asset Models: Merge all FX datasets (indexed by time) and repeat the process using cross-asset data. Do the same for stocks.\n",
    "\n",
    "Compare the performance of baseline and cross-asset models to determine if cross-asset data improves predictions.\n",
    "\n",
    "We decided to use  ElasticNet (L1/L2 balanced) alpha=0.000066, l1_ratio=0.5\n",
    "because our data is higly multicollinear because it i all derived from the same ohlc and also because ElasticNet can be a form of stepwise regression(feature selection) ,\n",
    "for both linear and logistic reg . \n",
    "\n",
    "Each regression method has metrics it records to be used for comparison between base and full\n",
    "\n",
    "Linear: adjusted Rsquared Accuracy and AIC, \n",
    "Logistic: Accuracy, Precision, Specificity, AIC\n",
    "\n",
    "For the results dataframe. the rows are each asset and each column is a result metric with suffix _base for base model and _full for full models\n",
    "\n",
    "different frames for linear and logistic results \n",
    "\n",
    "We then conduct sign test to test if the results from base columns are significantly different from cross   \n",
    "\n",
    "for each cross analysis we save a dictionary or JSON obj of its used features and columns with their absolute something value, this is for possible further analysis as shown by next two points\n",
    "\n",
    "1. for each model we should look at percentage of columns used since elastic net drops some columns, then for cross models , we should look at how many columns/features are from other assets and express it as a percentage of the features it uses.  \n",
    "\n",
    "2. Then maybe to take it a step furthur lets say EURUSD is correlated with symbols XYZ lets then see prevalance or dominance of those symbols in \n",
    "\n",
    "but these two points are a maybe. we will see ease of implementation when we get there. \n",
    "\n",
    "There will be no train test split for the data instead we train on the whole data and test on the whole data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Acquisition & Feature Engineering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import yfinance as yf\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math\n",
    "from sklearn.decomposition import PCA, KernelPCA, IncrementalPCA, FastICA\n",
    "from sklearn.manifold import Isomap, LocallyLinearEmbedding, MDS, TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import binomtest\n",
    "\n",
    "\n",
    "import talib as ta\n",
    "#I used a on wheels install of talib specific to the current python version i am using.\n",
    "#  Do so to if necessary in future\n",
    "# pip install talib will typically install the 32bit version of the package which is incompatible with\n",
    "# most 64 bit computers. So expect an error. The website below should have a command/release for \n",
    "# whatever python version you have. NOTE you must tailor the command to your version\n",
    "# https://github.com/cgohlke/talib-build?tab=readme-ov-file\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Define asset lists\n",
    "FX = [\n",
    "    \"EURUSD=X\", \"EURGBP=X\", \"GBPUSD=X\", \"USDJPY=X\",\n",
    "    \"AUDJPY=X\", \"EURJPY=X\", \"AUDUSD=X\", \"GBPAUD=X\",\n",
    "    \"USDCHF=X\", \"USDCAD=X\"\n",
    "]\n",
    "\n",
    "STOCKS = [\n",
    "    \"META\", \"AAPL\", \"AMZN\", \"NFLX\", \"GOOGL\",\n",
    "    \"JPM\", \"GS\", \"C\", \"AXP\"\n",
    "]\n",
    "\n",
    "SYMBOLS = FX + STOCKS\n",
    "\n",
    "# Parameters for data download\n",
    "START_DATE = \"2020-12-17\"\n",
    "END_DATE = \"2025-01-01\"\n",
    "INTERVAL = \"1d\"\n",
    "\n",
    "# Directory to save parquet files\n",
    "SAVE_DIR = \"new_yahoo_finance_data\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Download and pre processing\n",
    "def process_and_save_data(ticker):\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    df = yf.download(ticker, start=START_DATE, end=END_DATE, interval=INTERVAL)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"Data for {ticker} is empty. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    # Flattens the data, Keeps only Price Type\n",
    "    df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "    #Change index from date to numbers and retain a date column  \n",
    "    df.reset_index(inplace=True)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True)\n",
    "\n",
    "    # Create derived columns\n",
    "    df[\"weighted\"] = (df['Open'] + df['High'] + df['Low'] + df['Close']) / 4\n",
    "    df['ocDelta'] = df['Close'] - df['Open'] #open close delta\n",
    "    df['hlDelta'] = df['High'] - df['Low']\n",
    "    df['hl_oc'] = df['hlDelta'] / df['ocDelta']\n",
    "    df['Percent_Change'] = (df['ocDelta']/df[\"Open\"])*100\n",
    "    df['CandleDirection'] = (df['Close'] > df['Open']).astype(int)\n",
    "\n",
    "    # Replace infinite or NaN values\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "    ## FEATURE CREATION OF INDICATORS AND FORMATIONS\n",
    "\n",
    "    df[f'NextCandleDirectionR'] = df['Close'].shift(1) - df['Close']\n",
    "    df['NextCandleDirectionC'] = (df['NextCandleDirectionR'] > 0).astype(int)\n",
    "\n",
    "    #Averages\n",
    "    df[f\"SMA\"] = ta.SMA(df['weighted'], timeperiod=14)\n",
    "    df[f\"EMA\"] = ta.EMA(df['weighted'], timeperiod=14)\n",
    "    df[f\"DEMA\"] = ta.DEMA(df['weighted'], timeperiod=14)\n",
    "    df[f\"TEMA\"] = ta.TEMA(df['weighted'], timeperiod=14)\n",
    "    df[f\"ROC\"] = ta.ROC(df['weighted'], timeperiod=14)\n",
    "    df[f\"ATR\"] = ta.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    df[f\"NATR\"] = ta.NATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    upper, middle, lower = ta.BBANDS(df['weighted'], timeperiod=14)\n",
    "    df[f\"BBANDS_UPPER\"] = upper\n",
    "    df[f\"BBANDS_MIDDLE\"] = middle\n",
    "    df[f\"BBANDS_LOWER\"] = lower\n",
    "    #Deviations\n",
    "    df[\"w_SMA\"] = df[\"weighted\"]-df[f\"SMA\"]\n",
    "    df[\"w_UPPER\"] = df[\"weighted\"]-df[f\"BBANDS_UPPER\"]\n",
    "    df[\"w_LOWER\"] = df[\"weighted\"]-df[f\"BBANDS_LOWER\"]\n",
    "    df[f\"Aroon_Up\"], df[f\"Aroon_Down\"] = ta.AROON(df['High'], df['Low'], timeperiod=14)\n",
    "    df[f\"Aroon_Osc\"] = ta.AROONOSC(df['High'], df['Low'], timeperiod=14)\n",
    "    df[f\"ADX\"] = ta.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    df[f\"CCI\"] = ta.CCI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    df[f\"ROCP\"] = ta.ROCP(df['weighted'], timeperiod=14)\n",
    "    df[f\"WilliamsR\"] = ta.WILLR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    df[f\"ADOSC\"] = ta.ADOSC(df['High'], df['Low'], df['Close'], df['Volume'], fastperiod=14, slowperiod=14*2)\n",
    "    df['SAR'] = ta.SAR(df['High'].values, df['Low'].values)\n",
    "        \n",
    "    df = df.replace([np.inf, -np.inf,np.nan], 0)\n",
    "\n",
    "    df.drop(df.head(14).index,inplace=True)\n",
    "    df.drop(df.tail(1).index,inplace=True)\n",
    "    \n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df = df.replace([np.inf, -np.inf,np.nan], 0)\n",
    "    #Patterns\n",
    "    # Hammer\n",
    "    df[\"CDLHAMMER\"] = ta.CDLHAMMER(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "\n",
    "    # Inverted Hammer\n",
    "    df[\"CDLINVERTEDHAMMER\"] = ta.CDLINVERTEDHAMMER(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "\n",
    "    # Hanging Man\n",
    "    df[\"CDLHANGINGMAN\"] = ta.CDLHANGINGMAN(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "\n",
    "    # Shooting Star\n",
    "    df[\"CDLSHOOTINGSTAR\"] = ta.CDLSHOOTINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "\n",
    "    # Engulfing Pattern\n",
    "    df[\"CDLENGULFING\"] = ta.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "\n",
    "    # Harami Pattern\n",
    "    df[\"CDLHARAMI\"] = ta.CDLHARAMI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "\n",
    "    # Piercing Line\n",
    "    df[\"CDLPIERCING\"] = ta.CDLPIERCING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "\n",
    "    # Dark Cloud Cover\n",
    "    df[\"CDLDARKCLOUDCOVER\"] = ta.CDLDARKCLOUDCOVER(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"], penetration=0)\n",
    "\n",
    "    # Morning Star\n",
    "    df[\"CDLMORNINGSTAR\"] = ta.CDLMORNINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"], penetration=0)\n",
    "\n",
    "    # Evening Star\n",
    "    df[\"CDLEVENINGSTAR\"] = ta.CDLEVENINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"], penetration=0)\n",
    "\n",
    "\n",
    "    # Remove '=X' from ticker symbol for cleaner column names\n",
    "    clean_ticker = ticker.replace(\"=X\", \"\")\n",
    "    \n",
    "    # Rename columns to include ticker name\n",
    "    df.columns = [f\"{col}_{clean_ticker}\" if col != \"Date\" else \"Date\" for col in df.columns]\n",
    "    \n",
    "    # Save as Parquet\n",
    "    file_path = os.path.join(SAVE_DIR, f\"{clean_ticker}.parquet\")\n",
    "    df.to_parquet(file_path, engine=\"pyarrow\")\n",
    "    print(f\"Saved {ticker} as {file_path}\")\n",
    "\n",
    "# Download and process all assets\n",
    "for asset in tqdm(FX + STOCKS, desc=\"Downloading & Processing Data\"):\n",
    "    process_and_save_data(asset)\n",
    "\n",
    "#declare filtration function\n",
    "def FilterColumn(partial: list,df: (pd.core.frame.DataFrame),compliment: bool=False):\n",
    "  \"\"\"\n",
    "  Provides filtered list of columns\n",
    "\n",
    "  Uses list of keywords provided to filter columns of the df provided.\n",
    "  If compliment is on, the filter excludes the columns having the input\n",
    "  list of keywords. \n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  partial (list):list containing keywords/phrases/sections of column names  \n",
    "  df  (pandas.core.frame.DataFrame): dataframe in which columns are to be filtered\n",
    "  compliment (bool):False to include the columns containing the keywords, True to exclude such columns\n",
    "  \"\"\"\n",
    "\n",
    "  hasIt = []\n",
    "  hazIt = list(df.columns)\n",
    "  \n",
    "  for p in partial:\n",
    "    for column in df.columns:\n",
    "      if(compliment==False):\n",
    "        if(column.find(p)!=-1):\n",
    "          hasIt.append(column)\n",
    "\n",
    "      if(compliment==True):\n",
    "        if(column.find(p)!=-1):\n",
    "          hazIt.remove(column)\n",
    "\n",
    "  if(compliment==False):\n",
    "    return hasIt\n",
    "  if(compliment==True):\n",
    "    return hazIt\n",
    "\n",
    "#Merging data\n",
    "\n",
    "# Load FX data\n",
    "fx_dataframes = []\n",
    "for fx_ticker in FX:\n",
    "    clean_ticker = fx_ticker.replace(\"=X\", \"\")\n",
    "    file_path = os.path.join(SAVE_DIR, f\"{clean_ticker}.parquet\")\n",
    "    df = pd.read_parquet(file_path)\n",
    "    fx_dataframes.append(df)\n",
    "\n",
    "# Load Stock data\n",
    "stock_dataframes = []\n",
    "for stock_ticker in STOCKS:\n",
    "    file_path = os.path.join(SAVE_DIR, f\"{stock_ticker}.parquet\")\n",
    "    df = pd.read_parquet(file_path)\n",
    "    stock_dataframes.append(df)\n",
    "\n",
    "# Function to merge dataframes on the 'Date' column\n",
    "def merge_dataframes(dataframes):\n",
    "    merged_df = dataframes[0]  # Start with the first dataframe\n",
    "    for df in dataframes[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=\"Date\", how=\"inner\")\n",
    "    return merged_df\n",
    "\n",
    "# Merge FX dataframes\n",
    "fx_merged_df = merge_dataframes(fx_dataframes)\n",
    "fx_merged_df = fx_merged_df[FilterColumn([\"Volume\"],fx_merged_df,compliment=True)]\n",
    "# Merge Stock dataframes\n",
    "stock_merged_df = merge_dataframes(stock_dataframes)\n",
    "\n",
    "# Merge the FX and Stock dataframes on the 'Date' column\n",
    "combined_df = pd.merge(fx_merged_df, stock_merged_df, on=\"Date\", how=\"inner\")\n",
    "\n",
    "# Save the merged dataframes to Parquet files (optional)\n",
    "fx_merged_df.to_parquet(os.path.join(SAVE_DIR, \"fx_merged.parquet\"), engine=\"pyarrow\")\n",
    "stock_merged_df.to_parquet(os.path.join(SAVE_DIR, \"stock_merged.parquet\"), engine=\"pyarrow\")\n",
    "combined_df.to_parquet(os.path.join(SAVE_DIR, \"combined_fx_stock.parquet\"), engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Descriptive Statistics<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import merged data \n",
    "fx_df = pd.read_parquet(os.path.join(SAVE_DIR, \"fx_merged.parquet\"))\n",
    "stock_df = pd.read_parquet(os.path.join(SAVE_DIR, \"stock_merged.parquet\"))\n",
    "combined_df = pd.read_parquet(os.path.join(SAVE_DIR, \"combined_fx_stock.parquet\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: []\n",
      "Total rows with missing data: 0/1000\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_counts = combined_df.isnull().sum()\n",
    "columns_with_missing = missing_counts[missing_counts > 0].index.tolist()\n",
    "rows_with_missing = combined_df[combined_df.isnull().any(axis=1)].shape[0]\n",
    "\n",
    "print(f\"Columns with missing values: {columns_with_missing}\")\n",
    "print(f\"Total rows with missing data: {rows_with_missing}/{len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted price desc stats\n",
    "def weighted_price_stats(df, assets):\n",
    "    \"\"\"\n",
    "    Generate descriptive statistics for weighted price across assets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Merged DataFrame containing all assets\n",
    "    - assets: List of asset symbols (e.g., ['EURUSD', 'AAPL'])\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with assets as index and statistics as columns\n",
    "    \"\"\"\n",
    "    # Initialize stats dictionary\n",
    "    stats_list = []\n",
    "    \n",
    "    # Calculate statistics for each asset\n",
    "    for asset in assets:\n",
    "        col_name = f'weighted_{asset}'\n",
    "        if col_name not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        series = df[col_name].dropna()\n",
    "        if len(series) == 0:\n",
    "            continue\n",
    "            \n",
    "        stats = {\n",
    "            'Asset': asset,\n",
    "            'Mean': series.mean(),\n",
    "            'Median': series.median(),\n",
    "            'Min': series.min(),\n",
    "            'Max': series.max(),\n",
    "            'Std': series.std(),\n",
    "            'Var': series.var(),\n",
    "            'IQR': series.quantile(0.75) - series.quantile(0.25),\n",
    "            'Skew': series.skew(),\n",
    "            'Kurtosis': series.kurtosis(),\n",
    "            'Count': len(series),\n",
    "            '5th %ile': series.quantile(0.05),\n",
    "            '95th %ile': series.quantile(0.95),\n",
    "            'Range': series.max() - series.min(),\n",
    "            'CV': series.std() / series.mean()  # Coefficient of variation\n",
    "        }\n",
    "        stats_list.append(stats)\n",
    "    \n",
    "    # Create and format DataFrame\n",
    "    stats_df = pd.DataFrame(stats_list)\n",
    "    stats_df.set_index('Asset', inplace=True)\n",
    "    \n",
    "    # Reorder columns logically\n",
    "    col_order = [\n",
    "        'Count', 'Mean', 'Median', 'Std', 'Var', 'Min', 'Max', 'Range',\n",
    "        '5th %ile', '95th %ile', 'IQR', 'Skew', 'Kurtosis', 'CV'\n",
    "    ]\n",
    "    return stats_df[col_order]\n",
    "\n",
    "# Example usage:\n",
    "fx_symbols = [x.replace(\"=X\", \"\") for x in FX]\n",
    "stock_symbols = STOCKS\n",
    "\n",
    "# Get stats for FX and Stocks separately\n",
    "fx_stats = weighted_price_stats(fx_df, fx_symbols)\n",
    "stock_stats = weighted_price_stats(stock_df, stock_symbols)\n",
    "\n",
    "# Combine and add asset type marker\n",
    "fx_stats['Type'] = 'FX'\n",
    "stock_stats['Type'] = 'Stock'\n",
    "all_stats = pd.concat([fx_stats, stock_stats])\n",
    "\n",
    "# Format numeric columns\n",
    "float_cols = all_stats.select_dtypes(include=[float]).columns\n",
    "all_stats[float_cols] = all_stats[float_cols].round(4)\n",
    "\n",
    "# Display\n",
    "print(\"Weighted Price Descriptive Statistics\")\n",
    "print(\"=\"*60)\n",
    "display(all_stats.sort_values('Type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create visualisations skew\n",
    "def plot_skew_kurt(stats_df, save_path='figures/skew_kurt_plot.png'):\n",
    "    \"\"\"\n",
    "    Enhanced scatterplot of skewness vs kurtosis with:\n",
    "    - Boxes (□) for FX pairs\n",
    "    - Triangles (▲) for equities \n",
    "    - Unique colors per asset\n",
    "    - Professional formatting\n",
    "    - Saves as high-res PNG\n",
    "    \"\"\"\n",
    "    # Create directory if needed\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 7), dpi=300)  # High DPI for quality\n",
    "    \n",
    "    # Create style mappings\n",
    "    marker_map = {'FX': 's', 'Stock': '^'}  # □ for FX, ▲ for stocks\n",
    "    unique_assets = stats_df['Asset'].unique()\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_assets)))\n",
    "    \n",
    "    # Plot each asset\n",
    "    for i, asset in enumerate(unique_assets):\n",
    "        asset_data = stats_df[stats_df['Asset'] == asset]\n",
    "        plt.scatter(\n",
    "            x=asset_data['Skew'],\n",
    "            y=asset_data['Kurtosis'],\n",
    "            s=150,  # Marker size\n",
    "            marker=marker_map[asset_data['Type'].iloc[0]],\n",
    "            color=colors[i],\n",
    "            edgecolor='white',\n",
    "            linewidth=0.8,\n",
    "            alpha=0.9,\n",
    "            label=asset\n",
    "        )\n",
    "    \n",
    "    # Reference lines\n",
    "    plt.axvline(0, color='gray', linestyle=':', alpha=0.7)\n",
    "    plt.axhline(0, color='gray', linestyle=':', alpha=0.7)\n",
    "    \n",
    "    # Annotations\n",
    "    plt.text(0.5, 2.5, \"Fat Right Tails\", ha='center', fontsize=10, color='darkred')\n",
    "    plt.text(-0.5, 2.5, \"Fat Left Tails\", ha='center', fontsize=10, color='darkred')\n",
    "    \n",
    "    # Highlight special cases\n",
    "    for asset in ['GS', 'AXP', 'EURUSD']:  # Example highlights\n",
    "        if asset in stats_df['Asset'].values:\n",
    "            idx = stats_df[stats_df['Asset'] == asset].index[0]\n",
    "            plt.annotate(\n",
    "                asset, \n",
    "                (stats_df.loc[idx, 'Skew'], stats_df.loc[idx, 'Kurtosis']),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(8,5),\n",
    "                ha='left',\n",
    "                fontsize=9,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.7)\n",
    "            )\n",
    "    \n",
    "    # Styling\n",
    "    plt.title('Asset Return Distributions: Skewness vs Kurtosis', pad=20, fontsize=14)\n",
    "    plt.xlabel('Skewness → Positive = Right-Skewed', fontsize=12)\n",
    "    plt.ylabel('Excess Kurtosis → Positive = Fat Tails', fontsize=12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)\n",
    "    plt.grid(alpha=0.2)\n",
    "    sns.despine()\n",
    "    \n",
    "    # Save as high-quality PNG\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300, transparent=False)\n",
    "    plt.close()\n",
    "    print(f\"Saved to {save_path}\")\n",
    "\n",
    "# Usage\n",
    "plot_skew_kurt(all_stats.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create visualisations correlation\n",
    "corr_cmap = LinearSegmentedColormap.from_list(\n",
    "    'corr_cmap', ['#2A5CAA', 'white', '#B22222'])\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Filter to keep only continuous weighted price columns\"\"\"\n",
    "    return df[[col for col in df.columns if 'weighted_' in col]]\n",
    "\n",
    "def plot_correlation_matrix(df, title, figsize=(10,8)):\n",
    "    \"\"\"Plot cleaned correlation matrix\"\"\"\n",
    "    # Clean column names\n",
    "    df.columns = [col.replace('weighted_', '') for col in df.columns]\n",
    "    corr = df.corr()\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(\n",
    "        corr, \n",
    "        mask=mask,\n",
    "        cmap=corr_cmap,\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        annot_kws={'size':8},\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    plt.title(title, pad=20)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/{title.lower().replace(\" \", \"_\")}.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return corr\n",
    "\n",
    "def get_correlation_tiers(corr_matrix):\n",
    "    \"\"\"Identify correlation strength tiers\"\"\"\n",
    "    corr_pairs = corr_matrix.stack()\n",
    "    corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != \n",
    "                    corr_pairs.index.get_level_values(1)]  # Remove diagonal\n",
    "    \n",
    "    strong = corr_pairs[abs(corr_pairs) > 0.6].sort_values(ascending=False)\n",
    "    moderate = corr_pairs[(abs(corr_pairs) >= 0.3) & \n",
    "                         (abs(corr_pairs) <= 0.6)].sort_values(ascending=False)\n",
    "    \n",
    "    return strong, moderate\n",
    "\n",
    "# 1. FX vs FX correlations\n",
    "fx_cont = preprocess_data(fx_df)\n",
    "fx_corr = plot_correlation_matrix(fx_cont, \"FX Pairs Correlation Matrix\")\n",
    "fx_strong, fx_moderate = get_correlation_tiers(fx_corr)\n",
    "\n",
    "# 2. Stocks vs Stocks correlations\n",
    "stock_cont = preprocess_data(stock_df)\n",
    "stock_corr = plot_correlation_matrix(stock_cont, \"Equities Correlation Matrix\")\n",
    "stock_strong, stock_moderate = get_correlation_tiers(stock_corr)\n",
    "\n",
    "# 3. FX vs Stocks correlations\n",
    "combined = pd.concat([fx_cont, stock_cont], axis=1)\n",
    "cross_corr = combined.corr().loc[fx_cont.columns, stock_cont.columns]\n",
    "cross_corr.columns = [col.replace('weighted_', '') for col in cross_corr.columns]\n",
    "cross_corr.index = [col.replace('weighted_', '') for col in cross_corr.index]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(\n",
    "    cross_corr,\n",
    "    cmap=corr_cmap,\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    annot_kws={'size':8},\n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title(\"FX vs Equities Cross-Correlation\", pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/fx_vs_equities_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "cross_strong, cross_moderate = get_correlation_tiers(cross_corr)\n",
    "\n",
    "# Print correlation tiers\n",
    "print(\"=== STRONG CORRELATIONS ===\")\n",
    "print(\"FX Pairs:\\n\", fx_strong.to_string(), \"\\n\")\n",
    "print(\"Equities:\\n\", stock_strong.to_string(), \"\\n\")\n",
    "print(\"FX-Stocks:\\n\", cross_strong.to_string(), \"\\n\")\n",
    "\n",
    "print(\"=== MODERATE CORRELATIONS ===\")\n",
    "print(\"FX Pairs:\\n\", fx_moderate.to_string(), \"\\n\")\n",
    "print(\"Equities:\\n\", stock_moderate.to_string(), \"\\n\")\n",
    "print(\"FX-Stocks:\\n\", cross_moderate.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Inferrential Statistics<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocess</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Data and checking for multivariate normality\n",
    "\n",
    "# Exclude discrete/categorical columns (e.g., candlestick patterns)\n",
    "categorical_keywords = ['Date','CDL', 'CandleDirection','Next'] \n",
    "non_contin_cols = FilterColumn(categorical_keywords, combined_df, compliment=False)\n",
    "\n",
    "# Get continuous columns (numeric with >4 distinct values)\n",
    "continuous_cols = [\n",
    "    col for col in combined_df.columns \n",
    "    if col not in non_contin_cols \n",
    "    and np.issubdtype(combined_df[col].dtype, np.number)\n",
    "    and len(combined_df[col].unique()) > 4\n",
    "]\n",
    "\n",
    "continuous_cols\n",
    "\n",
    "#perform the Henze-Zirkler Multivariate Normality Test (H0: data is multivariate normal)\n",
    "from pingouin import multivariate_normality\n",
    "X_continuous = combined_df[continuous_cols]\n",
    "multivariate_normality(X_continuous, alpha=.05)\n",
    "\n",
    "#data isnt multivariate continous\n",
    "\n",
    "# Scale all continuous features uniformly\n",
    "scaler = RobustScaler()\n",
    "combined_df[continuous_cols] = scaler.fit_transform(combined_df[continuous_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Regressions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing assets:   0%|          | 0/19 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e-04, tolerance: 2.525e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:   5%|▌         | 1/19 [01:47<32:21, 107.88s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e-05, tolerance: 3.033e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  11%|█         | 2/19 [03:33<30:08, 106.39s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e-03, tolerance: 4.565e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e-03, tolerance: 4.565e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e-03, tolerance: 4.565e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.085e-04, tolerance: 4.565e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e-04, tolerance: 4.565e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  16%|█▌        | 3/19 [07:24<43:37, 163.57s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.338e-01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.609e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.528e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.418e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.291e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.334e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.152e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.585e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.822e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.195e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.652e+00, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+00, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.901e-01, tolerance: 6.903e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  21%|██        | 4/19 [17:03<1:21:50, 327.38s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.497e-01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.848e-01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.034e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.034e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.110e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.140e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.670e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.234e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.192e+00, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+00, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.800e-01, tolerance: 3.987e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  26%|██▋       | 5/19 [26:40<1:37:23, 417.43s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.743e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.795e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.728e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.536e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.970e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.673e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.599e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.593e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.067e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.587e+00, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.417e-01, tolerance: 7.157e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  32%|███▏      | 6/19 [35:37<1:39:16, 458.18s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e-06, tolerance: 2.038e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  37%|███▋      | 7/19 [37:25<1:08:44, 343.69s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e-04, tolerance: 7.366e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.797e-05, tolerance: 7.366e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  42%|████▏     | 8/19 [40:52<55:01, 300.16s/it]  c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.415e-04, tolerance: 2.013e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.726e-04, tolerance: 2.013e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e-04, tolerance: 2.013e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-04, tolerance: 2.013e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  47%|████▋     | 9/19 [43:44<43:20, 260.05s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.351e-04, tolerance: 2.868e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e-04, tolerance: 2.868e-06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  53%|█████▎    | 10/19 [45:51<32:49, 218.82s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.168e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.291e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.574e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.669e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.716e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.681e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.533e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.399e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.410e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.766e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e+03, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.774e+02, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+02, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.067e+01, tolerance: 6.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  58%|█████▊    | 11/19 [59:03<52:33, 394.24s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.683e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.280e+01, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.149e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.207e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.259e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.153e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+02, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+01, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+01, tolerance: 7.233e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  63%|██████▎   | 12/19 [1:08:27<52:01, 445.98s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.064e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.699e+01, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.388e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.419e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.437e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.285e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.598e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.453e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+02, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e+01, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.723e+01, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+01, tolerance: 9.765e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  68%|██████▊   | 13/19 [1:18:11<48:47, 487.90s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+04, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+04, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+04, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.587e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.098e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.753e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.857e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.975e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.095e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.227e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.374e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.442e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.453e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.401e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.196e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.111e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.460e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+03, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.450e+02, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+02, tolerance: 1.389e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  74%|███████▎  | 14/19 [1:32:05<49:22, 592.42s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.796e+01, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.258e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e+02, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.552e+01, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.086e+01, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.644e+00, tolerance: 6.066e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  79%|███████▉  | 15/19 [1:40:42<37:58, 569.63s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.386e+01, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.282e+01, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e+01, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+02, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+02, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+02, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+02, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e+02, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+02, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+02, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.790e+01, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.180e+00, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+00, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.642e+00, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.670e+00, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.384e+00, tolerance: 5.272e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  84%|████████▍ | 16/19 [1:49:47<28:06, 562.22s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.720e+01, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+01, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+03, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.728e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.292e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.956e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+02, tolerance: 3.623e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  89%|████████▉ | 17/19 [2:00:06<19:18, 579.19s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.141e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.375e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.327e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+00, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.259e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.090e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+01, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.946e+00, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.795e+00, tolerance: 8.120e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets:  95%|█████████▍| 18/19 [2:08:24<09:14, 554.81s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.348e+01, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+01, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.006e+00, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.296e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.294e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.219e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.988e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.686e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+02, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.340e+01, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+01, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.509e+00, tolerance: 9.956e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing assets: 100%|██████████| 19/19 [2:16:46<00:00, 431.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Linear Regression Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Adj_R2_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Adj_R2_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AIC_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AIC_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Features_used_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Features_used_full",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cross_asset_features_used",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cross_asset_pctage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Alpha_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Alpha_full",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "83c38620-7887-47f5-b464-ad5cbe0b6950",
       "rows": [
        [
         "EURUSD",
         "0.003736511145638353",
         "0.0024345790075585476",
         "0.4471262151049714",
         "0.7652848191650035",
         "0.4311834077135597",
         "0.6065763999091249",
         "-11123.20590337936",
         "-11229.962859136478",
         "28",
         "403",
         "380",
         "94.29280397022333",
         "1e-05",
         "1e-05"
        ],
        [
         "EURGBP",
         "0.003850373458165152",
         "0.0026328525087081925",
         "0.5112752266012135",
         "0.7714865823881366",
         "0.4982157773634248",
         "0.6156819794709569",
         "-11067.170266532054",
         "-11069.374832957903",
         "26",
         "405",
         "378",
         "93.33333333333333",
         "1e-05",
         "1e-05"
        ],
        [
         "GBPUSD",
         "0.004926337594435525",
         "0.0029835471863046874",
         "0.46834626399358736",
         "0.8049947285203688",
         "0.45018417984430004",
         "0.6611995370293016",
         "-10560.31889690788",
         "-10781.284710744649",
         "33",
         "424",
         "404",
         "95.28301886792453",
         "1e-05",
         "1e-05"
        ],
        [
         "USDJPY",
         "0.6227208617303841",
         "0.35222991165067874",
         "0.4382257332554764",
         "0.8202671426185705",
         "0.41782936464960674",
         "0.54543512778722",
         "-877.3138312174618",
         "-878.942317000869",
         "35",
         "604",
         "570",
         "94.37086092715232",
         "1e-05",
         "9.236708571873866e-05"
        ],
        [
         "AUDJPY",
         "0.475585226116679",
         "0.2640546244169698",
         "0.432733155788941",
         "0.8251288177854907",
         "0.4115269186221724",
         "0.6065398400173542",
         "-1414.418356643852",
         "-1553.1985731370823",
         "36",
         "555",
         "526",
         "94.77477477477477",
         "1e-05",
         "0.0001268961003167922"
        ],
        [
         "EURJPY",
         "0.6308520398367667",
         "0.3581838007712769",
         "0.4439501610262442",
         "0.8207452894695613",
         "0.4231632511580663",
         "0.5431748576022748",
         "-849.3678582801996",
         "-839.4180287112245",
         "36",
         "607",
         "574",
         "94.56342668863262",
         "1e-05",
         "9.236708571873866e-05"
        ],
        [
         "AUDUSD",
         "0.0034054152342111762",
         "0.0021314807045983855",
         "0.43108414764129166",
         "0.7771202062633434",
         "0.41827335055644876",
         "0.6402957771519873",
         "-11320.776796884866",
         "-11541.876748597962",
         "22",
         "380",
         "358",
         "94.21052631578948",
         "1e-05",
         "1e-05"
        ],
        [
         "GBPAUD",
         "0.006374362202707679",
         "0.003976314863094401",
         "0.44837182875129944",
         "0.7853482192199145",
         "0.4318798524974723",
         "0.6244533642744213",
         "-10052.942479153471",
         "-10198.799604808259",
         "29",
         "428",
         "404",
         "94.39252336448598",
         "1e-05",
         "1e-05"
        ],
        [
         "USDCHF",
         "0.0032137882986639954",
         "0.0020903027630670714",
         "0.48692820018129745",
         "0.782948893611064",
         "0.4721331328332814",
         "0.6433650406537055",
         "-11424.609764658171",
         "-11558.89272157098",
         "28",
         "391",
         "366",
         "93.60613810741688",
         "1e-05",
         "1e-05"
        ],
        [
         "USDCAD",
         "0.003977363347410605",
         "0.0025017376235815076",
         "0.4484640476088495",
         "0.7817939373093328",
         "0.43314360448687306",
         "0.631154218903593",
         "-11000.272309489274",
         "-11165.539478220739",
         "27",
         "408",
         "386",
         "94.6078431372549",
         "1e-05",
         "1e-05"
        ],
        [
         "META",
         "4.8344658871973",
         "3.4863526282824937",
         "0.6308639523229336",
         "0.8080305673378259",
         "0.6142605526889233",
         "0.6276165762533747",
         "3237.541309597047",
         "3465.7121950840924",
         "43",
         "484",
         "451",
         "93.18181818181817",
         "1e-05",
         "0.007880462815669913"
        ],
        [
         "AAPL",
         "1.3593206911889752",
         "0.8568169479894467",
         "0.7445431731706236",
         "0.8985038065515256",
         "0.733331901773723",
         "0.7426530526522186",
         "697.9701663751549",
         "900.9380410447005",
         "42",
         "605",
         "563",
         "93.05785123966942",
         "1e-05",
         "0.0002395026619987486"
        ],
        [
         "AMZN",
         "1.7107251356280628",
         "1.2718476950839024",
         "0.7002996365144838",
         "0.8343478750837752",
         "0.6871466425057151",
         "0.6957969250159768",
         "1157.8346731022195",
         "1390.9414423593519",
         "42",
         "455",
         "421",
         "92.52747252747253",
         "1e-05",
         "0.0030391953823131978"
        ],
        [
         "NFLX",
         "6.10057474354383",
         "5.471062856311102",
         "0.7320848658545769",
         "0.7845238779685297",
         "0.7203268348889471",
         "0.6959595396759339",
         "3700.7659739878063",
         "3980.9458080284944",
         "42",
         "291",
         "266",
         "91.40893470790378",
         "1e-05",
         "0.1"
        ],
        [
         "GOOGL",
         "1.3697119041154635",
         "1.0320230088562645",
         "0.6907253251582866",
         "0.824424198980017",
         "0.6771521419363932",
         "0.7152593746445405",
         "713.2008575187871",
         "829.0419244283786",
         "42",
         "383",
         "353",
         "92.16710182767625",
         "3.5622478902624444e-05",
         "0.005736152510448681"
        ],
        [
         "JPM",
         "1.0567627755059543",
         "0.7439969486355404",
         "0.7881837213127016",
         "0.89501031592455",
         "0.7788877090819111",
         "0.8106774469469774",
         "194.42049964488876",
         "298.5633090924558",
         "42",
         "445",
         "416",
         "93.48314606741573",
         "1e-05",
         "0.002212216291070448"
        ],
        [
         "GS",
         "2.7786395039321072",
         "1.9687305181020962",
         "0.7868775821770173",
         "0.8930114578036109",
         "0.7657763526895933",
         "0.7948530640034689",
         "2223.922841677652",
         "2310.777855951311",
         "90",
         "478",
         "395",
         "82.63598326359832",
         "1e-05",
         "0.0041753189365604"
        ],
        [
         "C",
         "0.34282920229264696",
         "0.2736009186734025",
         "0.8552642954906325",
         "0.9078160813395509",
         "0.7825699717220179",
         "0.7971547692912145",
         "-1473.0458166705735",
         "-1502.169471029909",
         "334",
         "545",
         "229",
         "42.018348623853214",
         "2.592943797404667e-05",
         "9.236708571873866e-05"
        ],
        [
         "AXP",
         "1.4443246289416711",
         "1.0432727815047074",
         "0.7904792621257901",
         "0.8906816331744702",
         "0.7810552122004857",
         "0.8161463830661545",
         "821.28365498123",
         "894.7253546065996",
         "43",
         "405",
         "373",
         "92.09876543209876",
         "1e-05",
         "0.005736152510448681"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_base</th>\n",
       "      <th>RMSE_full</th>\n",
       "      <th>R2_base</th>\n",
       "      <th>R2_full</th>\n",
       "      <th>Adj_R2_base</th>\n",
       "      <th>Adj_R2_full</th>\n",
       "      <th>AIC_base</th>\n",
       "      <th>AIC_full</th>\n",
       "      <th>Features_used_base</th>\n",
       "      <th>Features_used_full</th>\n",
       "      <th>Cross_asset_features_used</th>\n",
       "      <th>Cross_asset_pctage</th>\n",
       "      <th>Alpha_base</th>\n",
       "      <th>Alpha_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EURUSD</th>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.4471</td>\n",
       "      <td>0.7653</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>-11123.2059</td>\n",
       "      <td>-11229.9629</td>\n",
       "      <td>28</td>\n",
       "      <td>403</td>\n",
       "      <td>380</td>\n",
       "      <td>94.2928</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURGBP</th>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>-11067.1703</td>\n",
       "      <td>-11069.3748</td>\n",
       "      <td>26</td>\n",
       "      <td>405</td>\n",
       "      <td>378</td>\n",
       "      <td>93.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPUSD</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>-10560.3189</td>\n",
       "      <td>-10781.2847</td>\n",
       "      <td>33</td>\n",
       "      <td>424</td>\n",
       "      <td>404</td>\n",
       "      <td>95.2830</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDJPY</th>\n",
       "      <td>0.6227</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>0.4382</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5454</td>\n",
       "      <td>-877.3138</td>\n",
       "      <td>-878.9423</td>\n",
       "      <td>35</td>\n",
       "      <td>604</td>\n",
       "      <td>570</td>\n",
       "      <td>94.3709</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUDJPY</th>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.4115</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>-1414.4184</td>\n",
       "      <td>-1553.1986</td>\n",
       "      <td>36</td>\n",
       "      <td>555</td>\n",
       "      <td>526</td>\n",
       "      <td>94.7748</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURJPY</th>\n",
       "      <td>0.6309</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>0.8207</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>-849.3679</td>\n",
       "      <td>-839.4180</td>\n",
       "      <td>36</td>\n",
       "      <td>607</td>\n",
       "      <td>574</td>\n",
       "      <td>94.5634</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUDUSD</th>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.4311</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.4183</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>-11320.7768</td>\n",
       "      <td>-11541.8767</td>\n",
       "      <td>22</td>\n",
       "      <td>380</td>\n",
       "      <td>358</td>\n",
       "      <td>94.2105</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPAUD</th>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.4319</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>-10052.9425</td>\n",
       "      <td>-10198.7996</td>\n",
       "      <td>29</td>\n",
       "      <td>428</td>\n",
       "      <td>404</td>\n",
       "      <td>94.3925</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCHF</th>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.4869</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>-11424.6098</td>\n",
       "      <td>-11558.8927</td>\n",
       "      <td>28</td>\n",
       "      <td>391</td>\n",
       "      <td>366</td>\n",
       "      <td>93.6061</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCAD</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.4331</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>-11000.2723</td>\n",
       "      <td>-11165.5395</td>\n",
       "      <td>27</td>\n",
       "      <td>408</td>\n",
       "      <td>386</td>\n",
       "      <td>94.6078</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>META</th>\n",
       "      <td>4.8345</td>\n",
       "      <td>3.4864</td>\n",
       "      <td>0.6309</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.6143</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>3237.5413</td>\n",
       "      <td>3465.7122</td>\n",
       "      <td>43</td>\n",
       "      <td>484</td>\n",
       "      <td>451</td>\n",
       "      <td>93.1818</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.3593</td>\n",
       "      <td>0.8568</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>697.9702</td>\n",
       "      <td>900.9380</td>\n",
       "      <td>42</td>\n",
       "      <td>605</td>\n",
       "      <td>563</td>\n",
       "      <td>93.0579</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.7107</td>\n",
       "      <td>1.2718</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>1157.8347</td>\n",
       "      <td>1390.9414</td>\n",
       "      <td>42</td>\n",
       "      <td>455</td>\n",
       "      <td>421</td>\n",
       "      <td>92.5275</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>6.1006</td>\n",
       "      <td>5.4711</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>3700.7660</td>\n",
       "      <td>3980.9458</td>\n",
       "      <td>42</td>\n",
       "      <td>291</td>\n",
       "      <td>266</td>\n",
       "      <td>91.4089</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>1.3697</td>\n",
       "      <td>1.0320</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>713.2009</td>\n",
       "      <td>829.0419</td>\n",
       "      <td>42</td>\n",
       "      <td>383</td>\n",
       "      <td>353</td>\n",
       "      <td>92.1671</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPM</th>\n",
       "      <td>1.0568</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.8107</td>\n",
       "      <td>194.4205</td>\n",
       "      <td>298.5633</td>\n",
       "      <td>42</td>\n",
       "      <td>445</td>\n",
       "      <td>416</td>\n",
       "      <td>93.4831</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS</th>\n",
       "      <td>2.7786</td>\n",
       "      <td>1.9687</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.7949</td>\n",
       "      <td>2223.9228</td>\n",
       "      <td>2310.7779</td>\n",
       "      <td>90</td>\n",
       "      <td>478</td>\n",
       "      <td>395</td>\n",
       "      <td>82.6360</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.3428</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>-1473.0458</td>\n",
       "      <td>-1502.1695</td>\n",
       "      <td>334</td>\n",
       "      <td>545</td>\n",
       "      <td>229</td>\n",
       "      <td>42.0183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXP</th>\n",
       "      <td>1.4443</td>\n",
       "      <td>1.0433</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.7811</td>\n",
       "      <td>0.8161</td>\n",
       "      <td>821.2837</td>\n",
       "      <td>894.7254</td>\n",
       "      <td>43</td>\n",
       "      <td>405</td>\n",
       "      <td>373</td>\n",
       "      <td>92.0988</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE_base  RMSE_full  R2_base  R2_full  Adj_R2_base  Adj_R2_full  \\\n",
       "EURUSD     0.0037     0.0024   0.4471   0.7653       0.4312       0.6066   \n",
       "EURGBP     0.0039     0.0026   0.5113   0.7715       0.4982       0.6157   \n",
       "GBPUSD     0.0049     0.0030   0.4683   0.8050       0.4502       0.6612   \n",
       "USDJPY     0.6227     0.3522   0.4382   0.8203       0.4178       0.5454   \n",
       "AUDJPY     0.4756     0.2641   0.4327   0.8251       0.4115       0.6065   \n",
       "EURJPY     0.6309     0.3582   0.4440   0.8207       0.4232       0.5432   \n",
       "AUDUSD     0.0034     0.0021   0.4311   0.7771       0.4183       0.6403   \n",
       "GBPAUD     0.0064     0.0040   0.4484   0.7853       0.4319       0.6245   \n",
       "USDCHF     0.0032     0.0021   0.4869   0.7829       0.4721       0.6434   \n",
       "USDCAD     0.0040     0.0025   0.4485   0.7818       0.4331       0.6312   \n",
       "META       4.8345     3.4864   0.6309   0.8080       0.6143       0.6276   \n",
       "AAPL       1.3593     0.8568   0.7445   0.8985       0.7333       0.7427   \n",
       "AMZN       1.7107     1.2718   0.7003   0.8343       0.6871       0.6958   \n",
       "NFLX       6.1006     5.4711   0.7321   0.7845       0.7203       0.6960   \n",
       "GOOGL      1.3697     1.0320   0.6907   0.8244       0.6772       0.7153   \n",
       "JPM        1.0568     0.7440   0.7882   0.8950       0.7789       0.8107   \n",
       "GS         2.7786     1.9687   0.7869   0.8930       0.7658       0.7949   \n",
       "C          0.3428     0.2736   0.8553   0.9078       0.7826       0.7972   \n",
       "AXP        1.4443     1.0433   0.7905   0.8907       0.7811       0.8161   \n",
       "\n",
       "          AIC_base    AIC_full  Features_used_base  Features_used_full  \\\n",
       "EURUSD -11123.2059 -11229.9629                  28                 403   \n",
       "EURGBP -11067.1703 -11069.3748                  26                 405   \n",
       "GBPUSD -10560.3189 -10781.2847                  33                 424   \n",
       "USDJPY   -877.3138   -878.9423                  35                 604   \n",
       "AUDJPY  -1414.4184  -1553.1986                  36                 555   \n",
       "EURJPY   -849.3679   -839.4180                  36                 607   \n",
       "AUDUSD -11320.7768 -11541.8767                  22                 380   \n",
       "GBPAUD -10052.9425 -10198.7996                  29                 428   \n",
       "USDCHF -11424.6098 -11558.8927                  28                 391   \n",
       "USDCAD -11000.2723 -11165.5395                  27                 408   \n",
       "META     3237.5413   3465.7122                  43                 484   \n",
       "AAPL      697.9702    900.9380                  42                 605   \n",
       "AMZN     1157.8347   1390.9414                  42                 455   \n",
       "NFLX     3700.7660   3980.9458                  42                 291   \n",
       "GOOGL     713.2009    829.0419                  42                 383   \n",
       "JPM       194.4205    298.5633                  42                 445   \n",
       "GS       2223.9228   2310.7779                  90                 478   \n",
       "C       -1473.0458  -1502.1695                 334                 545   \n",
       "AXP       821.2837    894.7254                  43                 405   \n",
       "\n",
       "        Cross_asset_features_used  Cross_asset_pctage  Alpha_base  Alpha_full  \n",
       "EURUSD                        380             94.2928      0.0000      0.0000  \n",
       "EURGBP                        378             93.3333      0.0000      0.0000  \n",
       "GBPUSD                        404             95.2830      0.0000      0.0000  \n",
       "USDJPY                        570             94.3709      0.0000      0.0001  \n",
       "AUDJPY                        526             94.7748      0.0000      0.0001  \n",
       "EURJPY                        574             94.5634      0.0000      0.0001  \n",
       "AUDUSD                        358             94.2105      0.0000      0.0000  \n",
       "GBPAUD                        404             94.3925      0.0000      0.0000  \n",
       "USDCHF                        366             93.6061      0.0000      0.0000  \n",
       "USDCAD                        386             94.6078      0.0000      0.0000  \n",
       "META                          451             93.1818      0.0000      0.0079  \n",
       "AAPL                          563             93.0579      0.0000      0.0002  \n",
       "AMZN                          421             92.5275      0.0000      0.0030  \n",
       "NFLX                          266             91.4089      0.0000      0.1000  \n",
       "GOOGL                         353             92.1671      0.0000      0.0057  \n",
       "JPM                           416             93.4831      0.0000      0.0022  \n",
       "GS                            395             82.6360      0.0000      0.0042  \n",
       "C                             229             42.0183      0.0000      0.0001  \n",
       "AXP                           373             92.0988      0.0000      0.0057  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importance saved to linear_feature_importance.json\n"
     ]
    }
   ],
   "source": [
    "#Linear Regressions\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get clean symbol names\n",
    "symbols = [s.replace('=X', '') for s in SYMBOLS]\n",
    "\n",
    "# Define model parameters\n",
    "l1_ratioA = 0.5  # Fixed L1 ratio\n",
    "full_cols = FilterColumn(['Date','Next'], combined_df, compliment=True)\n",
    "\n",
    "# Define alpha search space (wider range with more steps)\n",
    "alphas = np.logspace(-5, -1, 30)  # From 1e-5 to 1e-1\n",
    "\n",
    "# Initialize results dataframe with all needed columns\n",
    "linear_results = pd.DataFrame(\n",
    "    index=symbols,\n",
    "    columns=[\n",
    "        'RMSE_base','RMSE_full', 'R2_base','R2_full', 'Adj_R2_base','Adj_R2_full', \n",
    "        'AIC_base','AIC_full', 'Features_used_base', 'Features_used_full',\n",
    "        'Cross_asset_features_used', 'Cross_asset_pctage', 'Alpha_base', 'Alpha_full'\n",
    "    ],\n",
    "    data=151515\n",
    ")\n",
    "\n",
    "# Initialize feature importance storage\n",
    "feature_importance = {\n",
    "    \"linear\": {\n",
    "        sym: {\n",
    "            \"base\": {},\n",
    "            \"full\": {}\n",
    "        } for sym in symbols\n",
    "    }\n",
    "}\n",
    "\n",
    "for symb in tqdm(symbols, desc=\"Processing assets\"):\n",
    "    # Prepare data for current symbol\n",
    "    base_cols = [s for s in full_cols if symb in s]\n",
    "    X_base = combined_df[base_cols]\n",
    "    X_full = combined_df[full_cols]\n",
    "    y = combined_df[f\"NextCandleDirectionR_{symb}\"]\n",
    "    \n",
    "    # ===== ALPHA OPTIMIZATION WITH CONVERGENCE HANDLING =====\n",
    "    def find_best_alpha(X, y, model_type='base'):\n",
    "        best_alpha = None\n",
    "        best_score = -np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            try:\n",
    "                model = ElasticNet(\n",
    "                    alpha=alpha, \n",
    "                    l1_ratio=l1_ratioA,\n",
    "                    random_state=42,\n",
    "                    max_iter=100000,\n",
    "                    selection='random'  # Helps with convergence\n",
    "                )\n",
    "                model.fit(X, y)\n",
    "                \n",
    "                # Calculate score (using R² adjusted for fair comparison)\n",
    "                n = X.shape[0]\n",
    "                p = np.sum(model.coef_ != 0)\n",
    "                r2 = model.score(X, y)\n",
    "                adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "                \n",
    "                if adj_r2 > best_score:\n",
    "                    best_score = adj_r2\n",
    "                    best_alpha = alpha\n",
    "                    best_model = model\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed for {symb} {model_type} with alpha {alpha:.2e}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        return best_alpha, best_model\n",
    "    \n",
    "    # Find best alpha for baseline and full models\n",
    "    best_alpha_base, base_model = find_best_alpha(X_base, y, 'base')\n",
    "    best_alpha_full, full_model = find_best_alpha(X_full, y, 'full')\n",
    "    \n",
    "    # ===== CALCULATE ALL METRICS AND STORE FEATURE IMPORTANCE =====\n",
    "    def calculate_metrics(model, X, y, alpha, model_type):\n",
    "        # Basic metrics\n",
    "        pred = model.predict(X)\n",
    "        rmse = np.sqrt(mean_squared_error(y, pred))\n",
    "        r2 = model.score(X, y)\n",
    "        \n",
    "        # Adjusted R²\n",
    "        n = X.shape[0]\n",
    "        p = np.sum(model.coef_ != 0)\n",
    "        adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "        \n",
    "        # AIC\n",
    "        RSS = np.sum((y - pred) ** 2)\n",
    "        aic = n * np.log(RSS / n) + 2 * p\n",
    "        \n",
    "        # Feature usage\n",
    "        features_used = np.sum(model.coef_ != 0)\n",
    "        \n",
    "        # Store feature importance\n",
    "        feature_importance[\"linear\"][symb][model_type] = {\n",
    "            col: float(coef)  # Convert numpy to native Python float\n",
    "            for col, coef in zip(X.columns, model.coef_)\n",
    "            if coef != 0  # Only store non-zero coefficients\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'Adj_R2': adj_r2,\n",
    "            'AIC': aic,\n",
    "            'Features_used': features_used,\n",
    "            'Alpha': alpha\n",
    "        }\n",
    "    \n",
    "    # Calculate and store baseline metrics\n",
    "    base_metrics = calculate_metrics(base_model, X_base, y, best_alpha_base, 'base')\n",
    "    linear_results.loc[symb, 'RMSE_base'] = base_metrics['RMSE']\n",
    "    linear_results.loc[symb, 'R2_base'] = base_metrics['R2']\n",
    "    linear_results.loc[symb, 'Adj_R2_base'] = base_metrics['Adj_R2']\n",
    "    linear_results.loc[symb, 'AIC_base'] = base_metrics['AIC']\n",
    "    linear_results.loc[symb, 'Features_used_base'] = base_metrics['Features_used']\n",
    "    linear_results.loc[symb, 'Alpha_base'] = base_metrics['Alpha']\n",
    "    \n",
    "    # Calculate and store full model metrics\n",
    "    full_metrics = calculate_metrics(full_model, X_full, y, best_alpha_full, 'full')\n",
    "    linear_results.loc[symb, 'RMSE_full'] = full_metrics['RMSE']\n",
    "    linear_results.loc[symb, 'R2_full'] = full_metrics['R2']\n",
    "    linear_results.loc[symb, 'Adj_R2_full'] = full_metrics['Adj_R2']\n",
    "    linear_results.loc[symb, 'AIC_full'] = full_metrics['AIC']\n",
    "    linear_results.loc[symb, 'Features_used_full'] = full_metrics['Features_used']\n",
    "    linear_results.loc[symb, 'Alpha_full'] = full_metrics['Alpha']\n",
    "    \n",
    "    # Cross-asset features\n",
    "    cross_features = sum(1 for col in X_full.columns[full_model.coef_ != 0] if symb not in col)\n",
    "    linear_results.loc[symb, 'Cross_asset_features_used'] = cross_features\n",
    "    linear_results.loc[symb, 'Cross_asset_pctage'] = (cross_features / full_metrics['Features_used'] * 100 \n",
    "                                                   if full_metrics['Features_used'] > 0 else 0)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nFinal Linear Regression Results:\")\n",
    "display(linear_results)\n",
    "\n",
    "# Save results\n",
    "linear_results.to_csv('linear_regression_results_optimized.csv')\n",
    "\n",
    "# Save feature importance\n",
    "with open('linear_feature_importance.json', 'w') as f:\n",
    "    json.dump(feature_importance, f, indent=2)\n",
    "\n",
    "print(\"\\nFeature importance saved to linear_feature_importance.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing assets:  11%|█         | 2/19 [55:35<7:36:50, 1612.37s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Processing assets:  21%|██        | 4/19 [1:20:55<4:20:26, 1041.73s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Processing assets:  32%|███▏      | 6/19 [1:46:35<3:12:25, 888.08s/it] c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Processing assets:  37%|███▋      | 7/19 [2:03:59<3:07:52, 939.34s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Processing assets:  47%|████▋     | 9/19 [2:40:57<2:52:09, 1032.96s/it]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Processing assets: 100%|██████████| 19/19 [4:44:43<00:00, 899.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Specificity_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AIC_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Features_used_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Alpha_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Accuracy_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Specificity_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AIC_full",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Features_used_full",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Alpha_full",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cross_asset_features_used",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cross_asset_pct",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3a9a89fe-951a-429d-8db8-d7115346f28a",
       "rows": [
        [
         "EURUSD",
         "0.677",
         "0.6839080459770115",
         "0.6597938144329897",
         "-1280",
         "36",
         "0.001623776739188721",
         "0.792",
         "0.8101010101010101",
         "0.8061855670103093",
         "-344",
         "619",
         "0.0026366508987303583",
         "584",
         "94.34571890145395"
        ],
        [
         "EURGBP",
         "0.72",
         "0.7211538461538461",
         "0.7040816326530612",
         "-1368",
         "35",
         "0.001",
         "0.768",
         "0.7791164658634538",
         "0.7755102040816326",
         "-88",
         "723",
         "0.001",
         "685",
         "94.74412171507606"
        ],
        [
         "GBPUSD",
         "0.753",
         "0.7564870259481038",
         "0.7540322580645161",
         "-1448",
         "28",
         "0.004281332398719396",
         "0.804",
         "0.8142857142857143",
         "0.8165322580645161",
         "-378",
         "614",
         "0.0026366508987303583",
         "575",
         "93.64820846905538"
        ],
        [
         "USDJPY",
         "0.713",
         "0.6644591611479028",
         "0.7304964539007093",
         "-1360",
         "32",
         "0.0026366508987303583",
         "0.784",
         "0.7340425531914894",
         "0.7783687943262412",
         "-138",
         "714",
         "0.001",
         "678",
         "94.9579831932773"
        ],
        [
         "AUDJPY",
         "0.689",
         "0.6659242761692651",
         "0.7222222222222222",
         "-1358",
         "9",
         "0.20691380811147903",
         "0.815",
         "0.7919320594479831",
         "0.8185185185185185",
         "-464",
         "582",
         "0.0026366508987303583",
         "553",
         "95.01718213058419"
        ],
        [
         "EURJPY",
         "0.711",
         "0.6858974358974359",
         "0.7262569832402235",
         "-1360",
         "30",
         "0.004281332398719396",
         "0.789",
         "0.7550607287449392",
         "0.7746741154562383",
         "-144",
         "716",
         "0.001",
         "682",
         "95.25139664804469"
        ],
        [
         "AUDUSD",
         "0.664",
         "0.6601941747572816",
         "0.6492985971943888",
         "-1254",
         "36",
         "0.001623776739188721",
         "0.816",
         "0.8322851153039832",
         "0.8396793587174348",
         "-380",
         "625",
         "0.0026366508987303583",
         "591",
         "94.56"
        ],
        [
         "GBPAUD",
         "0.546",
         "1.0",
         "1.0",
         "-1084",
         "3",
         "0.8858667904100823",
         "0.774",
         "0.7673956262425448",
         "0.7683168316831683",
         "-476",
         "535",
         "0.004281332398719396",
         "498",
         "93.0841121495327"
        ],
        [
         "USDCHF",
         "0.538",
         "1.0",
         "1.0",
         "-1070",
         "2",
         "0.3359818286283781",
         "0.78",
         "0.7590361445783133",
         "0.7701149425287356",
         "-110",
         "724",
         "0.001",
         "688",
         "95.02762430939227"
        ],
        [
         "USDCAD",
         "0.554",
         "0.6273291925465838",
         "0.8830409356725146",
         "-1096",
         "5",
         "0.3359818286283781",
         "0.796",
         "0.7870182555780934",
         "0.7953216374269005",
         "-166",
         "712",
         "0.001",
         "678",
         "95.2247191011236"
        ],
        [
         "META",
         "0.86",
         "0.9321608040201005",
         "0.9476744186046512",
         "-1698",
         "10",
         "0.3359818286283781",
         "0.9",
         "0.8983402489626556",
         "0.9050387596899225",
         "-368",
         "715",
         "0.001",
         "672",
         "93.98601398601399"
        ],
        [
         "AAPL",
         "0.86",
         "0.9156010230179028",
         "0.9383177570093458",
         "-1696",
         "11",
         "0.3359818286283781",
         "0.905",
         "0.9021739130434783",
         "0.9158878504672897",
         "-424",
         "692",
         "0.001",
         "650",
         "93.9306358381503"
        ],
        [
         "AMZN",
         "0.892",
         "0.8852459016393442",
         "0.8914728682170543",
         "-1718",
         "32",
         "0.004281332398719396",
         "0.888",
         "0.8940677966101694",
         "0.9031007751937985",
         "-394",
         "690",
         "0.001623776739188721",
         "648",
         "93.91304347826087"
        ],
        [
         "NFLX",
         "0.925",
         "0.9237113402061856",
         "0.9280155642023347",
         "-1772",
         "38",
         "0.0026366508987303583",
         "0.925",
         "0.9326315789473684",
         "0.9377431906614786",
         "-504",
         "672",
         "0.001623776739188721",
         "636",
         "94.64285714285714"
        ],
        [
         "GOOGL",
         "0.862",
         "0.8921568627450981",
         "0.9188191881918819",
         "-1700",
         "11",
         "0.3359818286283781",
         "0.909",
         "0.896328293736501",
         "0.9114391143911439",
         "-382",
         "717",
         "0.001",
         "675",
         "94.14225941422593"
        ],
        [
         "JPM",
         "0.897",
         "0.8881856540084389",
         "0.8998109640831758",
         "-1714",
         "39",
         "0.001",
         "0.922",
         "0.9171974522292994",
         "0.9262759924385633",
         "-404",
         "719",
         "0.001",
         "676",
         "94.01947148817803"
        ],
        [
         "GS",
         "0.91",
         "0.9055441478439425",
         "0.9106796116504854",
         "-1666",
         "76",
         "0.004281332398719396",
         "0.908",
         "0.906832298136646",
         "0.912621359223301",
         "-738",
         "538",
         "0.004281332398719396",
         "454",
         "84.38661710037175"
        ],
        [
         "C",
         "0.924",
         "0.9316770186335404",
         "0.9349112426035503",
         "-1166",
         "340",
         "0.001",
         "0.913",
         "0.9159836065573771",
         "0.9191321499013807",
         "-388",
         "718",
         "0.001",
         "378",
         "52.64623955431755"
        ],
        [
         "AXP",
         "0.848",
         "0.9249329758713136",
         "0.9472693032015066",
         "-1670",
         "12",
         "0.3359818286283781",
         "0.904",
         "0.9028077753779697",
         "0.9152542372881356",
         "-404",
         "701",
         "0.001",
         "659",
         "94.00855920114122"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_base</th>\n",
       "      <th>Precision_base</th>\n",
       "      <th>Specificity_base</th>\n",
       "      <th>AIC_base</th>\n",
       "      <th>Features_used_base</th>\n",
       "      <th>Alpha_base</th>\n",
       "      <th>Accuracy_full</th>\n",
       "      <th>Precision_full</th>\n",
       "      <th>Specificity_full</th>\n",
       "      <th>AIC_full</th>\n",
       "      <th>Features_used_full</th>\n",
       "      <th>Alpha_full</th>\n",
       "      <th>Cross_asset_features_used</th>\n",
       "      <th>Cross_asset_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EURUSD</th>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>-1280</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>0.8101</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>-344</td>\n",
       "      <td>619</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>584</td>\n",
       "      <td>94.3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURGBP</th>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>-1368</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>-88</td>\n",
       "      <td>723</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>685</td>\n",
       "      <td>94.7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPUSD</th>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>-1448</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>0.8165</td>\n",
       "      <td>-378</td>\n",
       "      <td>614</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>575</td>\n",
       "      <td>93.6482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDJPY</th>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>-1360</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>-138</td>\n",
       "      <td>714</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>678</td>\n",
       "      <td>94.9580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUDJPY</th>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>-1358</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>-464</td>\n",
       "      <td>582</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>553</td>\n",
       "      <td>95.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURJPY</th>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.7263</td>\n",
       "      <td>-1360</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>-144</td>\n",
       "      <td>716</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>682</td>\n",
       "      <td>95.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUDUSD</th>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>-1254</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>-380</td>\n",
       "      <td>625</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>591</td>\n",
       "      <td>94.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPAUD</th>\n",
       "      <td>0.5460</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-1084</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>-476</td>\n",
       "      <td>535</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>498</td>\n",
       "      <td>93.0841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCHF</th>\n",
       "      <td>0.5380</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-1070</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>-110</td>\n",
       "      <td>724</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>688</td>\n",
       "      <td>95.0276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCAD</th>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.6273</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>-1096</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>-166</td>\n",
       "      <td>712</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>678</td>\n",
       "      <td>95.2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>META</th>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.9477</td>\n",
       "      <td>-1698</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8983</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>-368</td>\n",
       "      <td>715</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>672</td>\n",
       "      <td>93.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>-1696</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>-424</td>\n",
       "      <td>692</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>650</td>\n",
       "      <td>93.9306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>-1718</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.8941</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>-394</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>648</td>\n",
       "      <td>93.9130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>-1772</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.9377</td>\n",
       "      <td>-504</td>\n",
       "      <td>672</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>636</td>\n",
       "      <td>94.6429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.8620</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>-1700</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.9114</td>\n",
       "      <td>-382</td>\n",
       "      <td>717</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>675</td>\n",
       "      <td>94.1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPM</th>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>-1714</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>-404</td>\n",
       "      <td>719</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>676</td>\n",
       "      <td>94.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS</th>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>-1666</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>-738</td>\n",
       "      <td>538</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>454</td>\n",
       "      <td>84.3866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>0.9349</td>\n",
       "      <td>-1166</td>\n",
       "      <td>340</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>-388</td>\n",
       "      <td>718</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>378</td>\n",
       "      <td>52.6462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXP</th>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>-1670</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>-404</td>\n",
       "      <td>701</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>659</td>\n",
       "      <td>94.0086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy_base  Precision_base  Specificity_base  AIC_base  \\\n",
       "EURUSD         0.6770          0.6839            0.6598     -1280   \n",
       "EURGBP         0.7200          0.7212            0.7041     -1368   \n",
       "GBPUSD         0.7530          0.7565            0.7540     -1448   \n",
       "USDJPY         0.7130          0.6645            0.7305     -1360   \n",
       "AUDJPY         0.6890          0.6659            0.7222     -1358   \n",
       "EURJPY         0.7110          0.6859            0.7263     -1360   \n",
       "AUDUSD         0.6640          0.6602            0.6493     -1254   \n",
       "GBPAUD         0.5460          1.0000            1.0000     -1084   \n",
       "USDCHF         0.5380          1.0000            1.0000     -1070   \n",
       "USDCAD         0.5540          0.6273            0.8830     -1096   \n",
       "META           0.8600          0.9322            0.9477     -1698   \n",
       "AAPL           0.8600          0.9156            0.9383     -1696   \n",
       "AMZN           0.8920          0.8852            0.8915     -1718   \n",
       "NFLX           0.9250          0.9237            0.9280     -1772   \n",
       "GOOGL          0.8620          0.8922            0.9188     -1700   \n",
       "JPM            0.8970          0.8882            0.8998     -1714   \n",
       "GS             0.9100          0.9055            0.9107     -1666   \n",
       "C              0.9240          0.9317            0.9349     -1166   \n",
       "AXP            0.8480          0.9249            0.9473     -1670   \n",
       "\n",
       "        Features_used_base  Alpha_base  Accuracy_full  Precision_full  \\\n",
       "EURUSD                  36      0.0016         0.7920          0.8101   \n",
       "EURGBP                  35      0.0010         0.7680          0.7791   \n",
       "GBPUSD                  28      0.0043         0.8040          0.8143   \n",
       "USDJPY                  32      0.0026         0.7840          0.7340   \n",
       "AUDJPY                   9      0.2069         0.8150          0.7919   \n",
       "EURJPY                  30      0.0043         0.7890          0.7551   \n",
       "AUDUSD                  36      0.0016         0.8160          0.8323   \n",
       "GBPAUD                   3      0.8859         0.7740          0.7674   \n",
       "USDCHF                   2      0.3360         0.7800          0.7590   \n",
       "USDCAD                   5      0.3360         0.7960          0.7870   \n",
       "META                    10      0.3360         0.9000          0.8983   \n",
       "AAPL                    11      0.3360         0.9050          0.9022   \n",
       "AMZN                    32      0.0043         0.8880          0.8941   \n",
       "NFLX                    38      0.0026         0.9250          0.9326   \n",
       "GOOGL                   11      0.3360         0.9090          0.8963   \n",
       "JPM                     39      0.0010         0.9220          0.9172   \n",
       "GS                      76      0.0043         0.9080          0.9068   \n",
       "C                      340      0.0010         0.9130          0.9160   \n",
       "AXP                     12      0.3360         0.9040          0.9028   \n",
       "\n",
       "        Specificity_full  AIC_full  Features_used_full  Alpha_full  \\\n",
       "EURUSD            0.8062      -344                 619      0.0026   \n",
       "EURGBP            0.7755       -88                 723      0.0010   \n",
       "GBPUSD            0.8165      -378                 614      0.0026   \n",
       "USDJPY            0.7784      -138                 714      0.0010   \n",
       "AUDJPY            0.8185      -464                 582      0.0026   \n",
       "EURJPY            0.7747      -144                 716      0.0010   \n",
       "AUDUSD            0.8397      -380                 625      0.0026   \n",
       "GBPAUD            0.7683      -476                 535      0.0043   \n",
       "USDCHF            0.7701      -110                 724      0.0010   \n",
       "USDCAD            0.7953      -166                 712      0.0010   \n",
       "META              0.9050      -368                 715      0.0010   \n",
       "AAPL              0.9159      -424                 692      0.0010   \n",
       "AMZN              0.9031      -394                 690      0.0016   \n",
       "NFLX              0.9377      -504                 672      0.0016   \n",
       "GOOGL             0.9114      -382                 717      0.0010   \n",
       "JPM               0.9263      -404                 719      0.0010   \n",
       "GS                0.9126      -738                 538      0.0043   \n",
       "C                 0.9191      -388                 718      0.0010   \n",
       "AXP               0.9153      -404                 701      0.0010   \n",
       "\n",
       "        Cross_asset_features_used  Cross_asset_pct  \n",
       "EURUSD                        584          94.3457  \n",
       "EURGBP                        685          94.7441  \n",
       "GBPUSD                        575          93.6482  \n",
       "USDJPY                        678          94.9580  \n",
       "AUDJPY                        553          95.0172  \n",
       "EURJPY                        682          95.2514  \n",
       "AUDUSD                        591          94.5600  \n",
       "GBPAUD                        498          93.0841  \n",
       "USDCHF                        688          95.0276  \n",
       "USDCAD                        678          95.2247  \n",
       "META                          672          93.9860  \n",
       "AAPL                          650          93.9306  \n",
       "AMZN                          648          93.9130  \n",
       "NFLX                          636          94.6429  \n",
       "GOOGL                         675          94.1423  \n",
       "JPM                           676          94.0195  \n",
       "GS                            454          84.3866  \n",
       "C                             378          52.6462  \n",
       "AXP                           659          94.0086  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importance saved to logistic_feature_importance.json\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegressions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize symbols and results structures\n",
    "symbols = [s.replace('=X', '') for s in SYMBOLS]\n",
    "full_cols = FilterColumn(['Date','Next'], combined_df, compliment=True)\n",
    "l1_ratioA = 0.5\n",
    "\n",
    "# Initialize results DataFrame\n",
    "logistic_results = pd.DataFrame(\n",
    "    index=symbols,\n",
    "    columns=[\n",
    "        'Accuracy_base', 'Precision_base', 'Specificity_base', 'AIC_base', \n",
    "        'Features_used_base', 'Alpha_base',\n",
    "        'Accuracy_full', 'Precision_full', 'Specificity_full', 'AIC_full',\n",
    "        'Features_used_full', 'Alpha_full',\n",
    "        'Cross_asset_features_used', 'Cross_asset_pct'\n",
    "    ],\n",
    "    data=151515\n",
    ")\n",
    "\n",
    "# Initialize feature storage dictionary\n",
    "feature_storage = {\n",
    "    \"logistic\": {\n",
    "        sym: {\"base\": {}, \"full\": {}} for sym in symbols\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define alpha search space\n",
    "alphas = np.logspace(-3, 1, 20)  # Wider range for logistic regression\n",
    "\n",
    "for symb in tqdm(symbols, desc=\"Processing assets\"):\n",
    "    # Prepare data\n",
    "    base_cols = [s for s in full_cols if symb in s]\n",
    "    X_base = combined_df[base_cols]\n",
    "    X_full = combined_df[full_cols]\n",
    "    y = combined_df[f\"NextCandleDirectionC_{symb}\"]\n",
    "    \n",
    "    # ===== ALPHA OPTIMIZATION =====\n",
    "    def find_best_logistic_alpha(X, y, model_type):\n",
    "        best_alpha = None\n",
    "        best_score = -np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            try:\n",
    "                model = LogisticRegression(\n",
    "                    penalty='elasticnet',\n",
    "                    solver='saga',\n",
    "                    l1_ratio=l1_ratioA,\n",
    "                    C=1/(alpha * len(y)),\n",
    "                    random_state=42,\n",
    "                    max_iter=10000,\n",
    "                    class_weight='balanced'\n",
    "                )\n",
    "                model.fit(X, y)\n",
    "                \n",
    "                # Use balanced accuracy as selection criteria\n",
    "                pred = model.predict(X)\n",
    "                tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "                specificity = tn / (tn + fp)\n",
    "                precision = precision_score(y, pred)\n",
    "                score = (accuracy_score(y, pred) + specificity + precision) / 3  # Combined metric\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_alpha = alpha\n",
    "                    best_model = model\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "        return best_alpha, best_model\n",
    "    \n",
    "    # Find optimal alphas\n",
    "    best_alpha_base, base_model = find_best_logistic_alpha(X_base, y, 'base')\n",
    "    best_alpha_full, full_model = find_best_logistic_alpha(X_full, y, 'full')\n",
    "    \n",
    "    # ===== METRIC CALCULATION =====\n",
    "    def calculate_logistic_metrics(model, X, y, alpha):\n",
    "        # Predictions\n",
    "        pred = model.predict(X)\n",
    "        proba = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Basic metrics\n",
    "        tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "        metrics = {\n",
    "            'Accuracy': accuracy_score(y, pred),\n",
    "            'Precision': precision_score(y, pred),\n",
    "            'Specificity': tn / (tn + fp),\n",
    "            'Features_used': np.sum(model.coef_ != 0),\n",
    "            'Alpha': alpha\n",
    "        }\n",
    "        \n",
    "        # AIC calculation\n",
    "        n = len(y)\n",
    "        k = np.sum(model.coef_ != 0) + 1\n",
    "        ll = model.score(X, y) * n  # Approximate log-likelihood\n",
    "        metrics['AIC'] = 2 * k - 2 * ll\n",
    "        \n",
    "        # Feature importance\n",
    "        features = {\n",
    "            col: float(coef) \n",
    "            for col, coef in zip(X.columns, model.coef_[0])\n",
    "            if coef != 0\n",
    "        }\n",
    "        \n",
    "        return metrics, features\n",
    "    \n",
    "    # Calculate and store baseline metrics\n",
    "    base_metrics, base_features = calculate_logistic_metrics(base_model, X_base, y, best_alpha_base)\n",
    "    for metric, value in base_metrics.items():\n",
    "        logistic_results.loc[symb, f'{metric}_base'] = value\n",
    "    feature_storage[\"logistic\"][symb][\"base\"] = base_features\n",
    "    \n",
    "    # Calculate and store full model metrics\n",
    "    full_metrics, full_features = calculate_logistic_metrics(full_model, X_full, y, best_alpha_full)\n",
    "    for metric, value in full_metrics.items():\n",
    "        logistic_results.loc[symb, f'{metric}_full'] = value\n",
    "    feature_storage[\"logistic\"][symb][\"full\"] = full_features\n",
    "    \n",
    "    # Cross-asset features\n",
    "    cross_features = sum(1 for col in full_features if symb not in col)\n",
    "    logistic_results.loc[symb, 'Cross_asset_features_used'] = cross_features\n",
    "    logistic_results.loc[symb, 'Cross_asset_pct'] = (cross_features / full_metrics['Features_used'] * 100 \n",
    "                                                   if full_metrics['Features_used'] > 0 else 0)\n",
    "\n",
    "# Save results\n",
    "logistic_results.to_csv('logistic_regression_results_optimized.csv')\n",
    "\n",
    "# Save feature importance\n",
    "with open('logistic_feature_importance.json', 'w') as f:\n",
    "    json.dump(feature_storage, f, indent=2)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "display(logistic_results)\n",
    "print(\"\\nFeature importance saved to logistic_feature_importance.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe visualisations\n",
    "#1. Scattergraph of predicted vs actual for both baseline and full\n",
    "#2. Confusion Matrix box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sign Test of Results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: p-value = 0.0000\n",
      "R²: p-value = 0.0001\n",
      "AIC: p-value = 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your results (replace with your path)\n",
    "df = pd.read_csv(\"linear_regression_results_optimized.csv\")\n",
    "\n",
    "# Compute differences (Full - Base)\n",
    "df[\"RMSE_diff\"] = df[\"RMSE_full\"] - df[\"RMSE_base\"]  # Lower RMSE = better → Negative diff = improvement\n",
    "df[\"Adj_R2_diff\"] = df[\"Adj_R2_full\"] - df[\"Adj_R2_base\"]        # Higher R² = better → Positive diff = improvement\n",
    "df[\"AIC_diff\"] = df[\"AIC_full\"] - df[\"AIC_base\"]     # Lower AIC = better → Negative diff = improvement\n",
    "\n",
    "n_better_rmse = (df[\"RMSE_diff\"] < 0).sum()  # Count where Full model has lower RMSE\n",
    "n_total_rmse = (df[\"RMSE_diff\"] != 0).sum()  # Ignore ties (if any)\n",
    "\n",
    "# One-sided test: Is Full model better more often than chance?\n",
    "result_rmse = binomtest(n_better_rmse, n_total_rmse, p=0.5, alternative='two-sided')\n",
    "print(f\"RMSE: p-value = {result_rmse.pvalue:.4f}\")\n",
    "\n",
    "n_better_Adj_R2 = (df[\"Adj_R2_diff\"] > 0).sum()  # Count where Full model has higher R²\n",
    "n_total_Adj_R2 = (df[\"Adj_R2_diff\"] != 0).sum()  # Ignore ties\n",
    "\n",
    "result_Adj_R2 = binomtest(n_better_Adj_R2, n_total_Adj_R2, p=0.5, alternative='two-sided')\n",
    "print(f\"Adj_R²: p-value = {result_Adj_R2.pvalue:.4f}\")\n",
    "\n",
    "n_better_aic = (df[\"AIC_diff\"] < 0).sum()  # Count where Full model has lower AIC\n",
    "n_total_aic = (df[\"AIC_diff\"] != 0).sum()  # Ignore ties\n",
    "\n",
    "result_aic = binomtest(n_better_aic, n_total_aic, p=0.5, alternative='two-sided')\n",
    "print(f\"AIC: p-value = {result_aic.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: p-value = 0.0075\n",
      "Precision: p-value = 0.1671\n",
      "Specificity: p-value = 0.6476\n",
      "AIC: p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"logistic_regression_results_optimized.csv\")\n",
    "df.columns\n",
    "\n",
    "df[\"Accuracy_diff\"] = df[\"Accuracy_full\"] - df[\"Accuracy_base\"]\n",
    "n_better_Accuracy = (df[\"Accuracy_diff\"] < 0).sum()  # Count where Full model has lower Accuracy\n",
    "n_total_Accuracy = (df[\"Accuracy_diff\"] != 0).sum()  # Ignore ties (if any)\n",
    "result_Accuracy = binomtest(n_better_Accuracy, n_total_Accuracy, p=0.5, alternative='two-sided')\n",
    "print(f\"Accuracy: p-value = {result_Accuracy.pvalue:.4f}\")\n",
    "\n",
    "df[\"Precision_diff\"] = df[\"Precision_full\"] - df[\"Precision_base\"]\n",
    "n_better_Precision = (df[\"Precision_diff\"] < 0).sum()  # Count where Full model has lower Precision\n",
    "n_total_Precision = (df[\"Precision_diff\"] != 0).sum()  # Ignore ties (if any)\n",
    "result_Precision = binomtest(n_better_Precision, n_total_Precision, p=0.5, alternative='two-sided')\n",
    "print(f\"Precision: p-value = {result_Precision.pvalue:.4f}\")\n",
    "\n",
    "df[\"Specificity_diff\"] = df[\"Specificity_full\"] - df[\"Specificity_base\"]\n",
    "n_better_Specificity = (df[\"Specificity_diff\"] < 0).sum()  # Count where Full model has lower Specificity\n",
    "n_total_Specificity = (df[\"Specificity_diff\"] != 0).sum()  # Ignore ties (if any)\n",
    "result_Specificity = binomtest(n_better_Specificity, n_total_Specificity, p=0.5, alternative='two-sided')\n",
    "print(f\"Specificity: p-value = {result_Specificity.pvalue:.4f}\")\n",
    "\n",
    "df[\"AIC_diff\"] = df[\"AIC_full\"] - df[\"AIC_base\"]\n",
    "n_better_AIC = (df[\"AIC_diff\"] < 0).sum()  # Count where Full model has lower AIC\n",
    "n_total_AIC = (df[\"AIC_diff\"] != 0).sum()  # Ignore ties (if any)\n",
    "result_AIC = binomtest(n_better_AIC, n_total_AIC, p=0.5, alternative='two-sided')\n",
    "print(f\"AIC: p-value = {result_AIC.pvalue:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
